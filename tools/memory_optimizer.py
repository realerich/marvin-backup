#!/usr/bin/env python3
"""
è®°å¿†å±‚ä¼˜åŒ–ç³»ç»Ÿ - å…³è”è®°å¿† + è‡ªåŠ¨æ‘˜è¦ + æ··åˆæ£€ç´¢
"""

import json
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import numpy as np

# å°è¯•å¯¼å…¥ç°æœ‰å·¥å…·
try:
    from rds_manager import RDSManager
    RDS_AVAILABLE = True
except:
    RDS_AVAILABLE = False

class MemoryOptimizer:
    """è®°å¿†ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        if RDS_AVAILABLE:
            self.rds = RDSManager()
        self.workspace = Path("/root/.openclaw/workspace")
    
    def init_enhanced_tables(self):
        """åˆå§‹åŒ–å¢å¼ºç‰ˆè®°å¿†è¡¨"""
        if not RDS_AVAILABLE:
            print("âŒ RDSä¸å¯ç”¨")
            return False
        
        sql_statements = [
            # è®°å¿†å…³è”è¡¨
            """
            CREATE TABLE IF NOT EXISTS memory_links (
                id SERIAL PRIMARY KEY,
                source_memory_id INTEGER REFERENCES memories(id) ON DELETE CASCADE,
                target_memory_id INTEGER REFERENCES memories(id) ON DELETE CASCADE,
                link_type VARCHAR(50) DEFAULT 'related',
                strength NUMERIC(3, 2) DEFAULT 0.5,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(source_memory_id, target_memory_id, link_type)
            );
            CREATE INDEX IF NOT EXISTS idx_memory_links_source ON memory_links(source_memory_id);
            CREATE INDEX IF NOT EXISTS idx_memory_links_target ON memory_links(target_memory_id);
            """,
            
            # è®°å¿†æ‘˜è¦è¡¨
            """
            CREATE TABLE IF NOT EXISTS memory_summaries (
                id SERIAL PRIMARY KEY,
                summary_date DATE UNIQUE,
                content_summary TEXT,
                key_decisions JSONB,
                action_items JSONB,
                people_mentioned JSONB,
                topics JSONB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,
            
            # è®°å¿†è®¿é—®ç»Ÿè®¡è¡¨ï¼ˆç”¨äºä¸»åŠ¨å›å¿†ï¼‰
            """
            CREATE TABLE IF NOT EXISTS memory_access_patterns (
                id SERIAL PRIMARY KEY,
                hour_of_day INTEGER,
                day_of_week INTEGER,
                category VARCHAR(50),
                access_count INTEGER DEFAULT 0,
                last_accessed TIMESTAMP,
                UNIQUE(hour_of_day, day_of_week, category)
            );
            """,
            
            # ä¸ºmemoriesè¡¨æ·»åŠ æ–°å­—æ®µ
            """
            ALTER TABLE memories 
            ADD COLUMN IF NOT EXISTS tier INTEGER DEFAULT 2,
            ADD COLUMN IF NOT EXISTS decay_rate NUMERIC(3, 2) DEFAULT 0.1,
            ADD COLUMN IF NOT EXISTS summary TEXT,
            ADD COLUMN IF NOT EXISTS related_topics JSONB DEFAULT '[]'::jsonb;
            """,
            
            # åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•ï¼ˆä½¿ç”¨simpleé…ç½®ï¼Œé€‚é…PostgreSQLé»˜è®¤ï¼‰
            """
            CREATE INDEX IF NOT EXISTS idx_memories_content_fts ON memories 
            USING gin(to_tsvector('simple', content));
            """
        ]
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                for sql in sql_statements:
                    try:
                        cursor.execute(sql)
                        conn.commit()
                    except Exception as e:
                        print(f"âš ï¸ è¡¨å¯èƒ½å·²å­˜åœ¨æˆ–é”™è¯¯: {e}")
                        conn.rollback()
        
        print("âœ… å¢å¼ºè®°å¿†è¡¨åˆå§‹åŒ–å®Œæˆ")
        return True
    
    def create_memory_link(self, source_id: int, target_id: int, 
                          link_type: str = 'related', strength: float = 0.5):
        """åˆ›å»ºè®°å¿†å…³è”"""
        if not RDS_AVAILABLE:
            return False
        
        sql = """
        INSERT INTO memory_links (source_memory_id, target_memory_id, link_type, strength)
        VALUES (%s, %s, %s, %s)
        ON CONFLICT (source_memory_id, target_memory_id, link_type) DO UPDATE
        SET strength = EXCLUDED.strength
        """
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql, (source_id, target_id, link_type, strength))
                conn.commit()
        return True
    
    def find_related_memories(self, memory_id: int, min_strength: float = 0.3):
        """æŸ¥æ‰¾å…³è”è®°å¿†"""
        if not RDS_AVAILABLE:
            return []
        
        sql = """
        SELECT m.*, ml.link_type, ml.strength
        FROM memory_links ml
        JOIN memories m ON ml.target_memory_id = m.id
        WHERE ml.source_memory_id = %s AND ml.strength >= %s
        UNION
        SELECT m.*, ml.link_type, ml.strength
        FROM memory_links ml
        JOIN memories m ON ml.source_memory_id = m.id
        WHERE ml.target_memory_id = %s AND ml.strength >= %s
        ORDER BY strength DESC
        LIMIT 10
        """
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql, (memory_id, min_strength, memory_id, min_strength))
                return cursor.fetchall()
    
    def auto_link_memories(self):
        """è‡ªåŠ¨åˆ›å»ºè®°å¿†å…³è”"""
        if not RDS_AVAILABLE:
            return 0
        
        # 1. è·å–è¿‘æœŸè®°å¿†
        sql = """
        SELECT id, content, category, keywords, created_at
        FROM memories
        WHERE created_at > NOW() - INTERVAL '7 days'
        ORDER BY created_at DESC
        LIMIT 100
        """
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql)
                memories = cursor.fetchall()
        
        links_created = 0
        
        # 2. åŸºäºç›¸ä¼¼åº¦åˆ›å»ºå…³è”
        for i, m1 in enumerate(memories):
            for m2 in memories[i+1:]:
                similarity = self._calculate_similarity(m1, m2)
                if similarity > 0.6:
                    link_type = self._determine_link_type(m1, m2)
                    if self.create_memory_link(m1[0], m2[0], link_type, similarity):
                        links_created += 1
        
        return links_created
    
    def _calculate_similarity(self, m1, m2):
        """è®¡ç®—ä¸¤æ®µè®°å¿†çš„ç›¸ä¼¼åº¦"""
        # åŸºäºå…³é”®è¯é‡å  + æ—¶é—´æ¥è¿‘åº¦ + ç±»åˆ«ç›¸åŒ
        score = 0.0
        
        # ç±»åˆ«ç›¸åŒ +0.3
        if m1[2] == m2[2]:  # category
            score += 0.3
        
        # å…³é”®è¯é‡å 
        try:
            k1 = set(json.loads(m1[3]) if m1[3] else [])
            k2 = set(json.loads(m2[3]) if m2[3] else [])
            if k1 and k2:
                overlap = len(k1 & k2) / max(len(k1), len(k2))
                score += overlap * 0.4
        except:
            pass
        
        # å†…å®¹ç›¸ä¼¼åº¦ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
        c1, c2 = m1[1].lower(), m2[1].lower()
        common_words = set(c1.split()) & set(c2.split())
        if len(common_words) > 3:
            score += 0.2
        
        # æ—¶é—´æ¥è¿‘åº¦ï¼ˆåŒä¸€å¤©+0.1ï¼‰
        try:
            t1 = m1[4]
            t2 = m2[4]
            if abs((t1 - t2).days) <= 1:
                score += 0.1
        except:
            pass
        
        return min(score, 1.0)
    
    def _determine_link_type(self, m1, m2):
        """ç¡®å®šå…³è”ç±»å‹"""
        # ç®€å•å¯å‘å¼è§„åˆ™
        if 'RDS' in m1[1] and 'RDS' in m2[1]:
            return 'same_topic'
        if m1[2] == m2[2]:
            return 'same_category'
        return 'related'
    
    def generate_daily_summary(self, date_str: str = None):
        """ç”Ÿæˆæ¯æ—¥æ‘˜è¦"""
        if not RDS_AVAILABLE:
            return None
        
        if not date_str:
            date_str = datetime.now().strftime('%Y-%m-%d')
        
        # 1. è·å–å½“æ—¥è®°å¿†
        sql = """
        SELECT * FROM memories
        WHERE DATE(created_at) = %s
        ORDER BY importance_score DESC
        """
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql, (date_str,))
                memories = cursor.fetchall()
        
        if not memories:
            return None
        
        # 2. æå–å…³é”®ä¿¡æ¯
        key_decisions = []
        action_items = []
        people = set()
        topics = set()
        
        for m in memories:
            content = m[4]  # content
            
            # æ£€æµ‹å†³ç­–ï¼ˆåŒ…å«"å†³å®š"ã€"é€‰æ‹©"ç­‰è¯ï¼‰
            if any(w in content for w in ['å†³å®š', 'é€‰æ‹©', 'ç¡®å®š', 'å®Œæˆ', 'åˆ›å»º', 'é…ç½®']):
                key_decisions.append(content[:100])
            
            # æ£€æµ‹è¡ŒåŠ¨é¡¹ï¼ˆåŒ…å«"TODO"ã€"å¾…åŠ"ç­‰ï¼‰
            if any(w in content for w in ['TODO', 'å¾…åŠ', 'éœ€è¦', 'è®¡åˆ’']):
                action_items.append(content[:100])
            
            # æå–äººå/è§’è‰²ï¼ˆç®€å•è§„åˆ™ï¼‰
            words = re.findall(r'[\u4e00-\u9fa5]{2,4}', content)
            for w in words:
                if w in ['å¤§ç‹', 'Marvin', 'ç”¨æˆ·', 'ç®¡ç†å‘˜']:
                    people.add(w)
            
            # æå–ä¸»é¢˜
            if m[3]:  # category
                topics.add(m[3])
        
        # 3. ç”Ÿæˆæ‘˜è¦æ–‡æœ¬
        content_summary = f"ä»Šæ—¥å…±è®°å½• {len(memories)} æ¡è®°å¿†ã€‚"
        if key_decisions:
            content_summary += f" å…³é”®å†³ç­–: {len(key_decisions)} é¡¹ã€‚"
        if action_items:
            content_summary += f" å¾…åŠäº‹é¡¹: {len(action_items)} é¡¹ã€‚"
        
        # 4. ä¿å­˜æ‘˜è¦
        sql = """
        INSERT INTO memory_summaries 
        (summary_date, content_summary, key_decisions, action_items, people_mentioned, topics)
        VALUES (%s, %s, %s, %s, %s, %s)
        ON CONFLICT (summary_date) DO UPDATE SET
        content_summary = EXCLUDED.content_summary,
        key_decisions = EXCLUDED.key_decisions,
        action_items = EXCLUDED.action_items
        """
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql, (
                    date_str,
                    content_summary,
                    json.dumps(key_decisions[:10]),
                    json.dumps(action_items[:10]),
                    json.dumps(list(people)),
                    json.dumps(list(topics))
                ))
                conn.commit()
        
        return {
            'date': date_str,
            'total_memories': len(memories),
            'key_decisions': key_decisions,
            'action_items': action_items,
            'people': list(people),
            'topics': list(topics)
        }
    
    def hybrid_search(self, query: str, top_k: int = 10):
        """æ··åˆæ£€ç´¢ï¼šå‘é‡ + å…³é”®è¯ + SQL"""
        if not RDS_AVAILABLE:
            return []
        
        results = []
        
        # 1. å…¨æ–‡æœç´¢ï¼ˆPostgreSQLå†…ç½®ï¼‰
        sql_fts = """
        SELECT *, ts_rank(to_tsvector('simple', content), plainto_tsquery('simple', %s)) as rank
        FROM memories
        WHERE to_tsvector('simple', content) @@ plainto_tsquery('simple', %s)
        ORDER BY rank DESC
        LIMIT %s
        """
        
        # 2. å…³é”®è¯æ¨¡ç³ŠåŒ¹é…
        sql_like = """
        SELECT * FROM memories
        WHERE content ILIKE %s OR keywords::text ILIKE %s
        ORDER BY importance_score DESC, created_at DESC
        LIMIT %s
        """
        
        # 3. å…³è”è®°å¿†æœç´¢ï¼ˆé€šè¿‡å…³é”®è¯åŒ¹é…ï¼‰
        sql_related = """
        SELECT m.*, ml.strength as link_score
        FROM memories m
        JOIN memory_links ml ON m.id = ml.target_memory_id
        WHERE ml.source_memory_id IN (
            SELECT id FROM memories 
            WHERE content ILIKE %s 
            ORDER BY created_at DESC LIMIT 5
        )
        ORDER BY ml.strength DESC
        LIMIT %s
        """
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                # æ‰§è¡Œä¸‰ç§æœç´¢
                try:
                    cursor.execute(sql_fts, (query, query, top_k))
                    fts_results = cursor.fetchall()
                except:
                    fts_results = []
                
                cursor.execute(sql_like, (f'%{query}%', f'%{query}%', top_k))
                like_results = cursor.fetchall()
                
                try:
                    cursor.execute(sql_related, (f'%{query}%', top_k))
                    related_results = cursor.fetchall()
                except:
                    related_results = []
        
        # 4. RRFèåˆæ’åº
        combined = self._reciprocal_rank_fusion(
            fts_results, like_results, related_results
        )
        
        return combined[:top_k]
    
    def _reciprocal_rank_fusion(self, *result_lists):
        """RRFèåˆç®—æ³•"""
        k = 60  # RRFå¸¸æ•°
        scores = {}
        
        for results in result_lists:
            for rank, item in enumerate(results):
                item_id = item[0]  # id
                if item_id not in scores:
                    scores[item_id] = {'item': item, 'score': 0}
                scores[item_id]['score'] += 1.0 / (k + rank + 1)
        
        # æ’åº
        sorted_results = sorted(scores.values(), 
                               key=lambda x: x['score'], 
                               reverse=True)
        return [r['item'] for r in sorted_results]
    
    def proactive_recall(self, query: str = None):
        """ä¸»åŠ¨å›å¿†ï¼šåŸºäºå½“å‰æŸ¥è¯¢å’Œæ—¶é—´æ¨¡å¼å»ºè®®ç›¸å…³è®°å¿†"""
        if not RDS_AVAILABLE:
            return []
        
        suggestions = []
        now = datetime.now()
        
        # 1. åŸºäºæ—¶é—´æ¨¡å¼çš„å»ºè®®
        sql_pattern = """
        SELECT category, SUM(access_count) as total
        FROM memory_access_patterns
        WHERE hour_of_day = %s AND day_of_week = %s
        GROUP BY category
        ORDER BY total DESC
        LIMIT 3
        """
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql_pattern, (now.hour, now.weekday()))
                patterns = cursor.fetchall()
                
                for p in patterns:
                    # è·å–è¯¥ç±»åˆ«çš„æœ€æ–°è®°å¿†
                    cursor.execute("""
                        SELECT * FROM memories
                        WHERE category = %s
                        ORDER BY last_accessed DESC NULLS LAST
                        LIMIT 2
                    """, (p[0],))
                    suggestions.extend(cursor.fetchall())
        
        # 2. åŸºäºæŸ¥è¯¢å…³é”®è¯çš„å»ºè®®
        if query:
            # æå–å…³é”®è¯
            keywords = self._extract_keywords(query)
            if keywords:
                sql = """
                SELECT * FROM memories
                WHERE content ILIKE ANY(%s)
                ORDER BY importance_score DESC, created_at DESC
                LIMIT 3
                """
                
                with self.rds.get_connection() as conn:
                    with conn.cursor() as cursor:
                        patterns = [f'%{k}%' for k in keywords[:3]]
                        cursor.execute(sql, (patterns,))
                        suggestions.extend(cursor.fetchall())
        
        # å»é‡
        seen = set()
        unique_suggestions = []
        for s in suggestions:
            if s[0] not in seen:
                seen.add(s[0])
                unique_suggestions.append(s)
        
        return unique_suggestions[:5]
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        words = re.findall(r'[\u4e00-\u9fa5]{2,}|[a-zA-Z]{3,}', text.lower())
        # ç®€å•é¢‘ç‡ç»Ÿè®¡
        freq = {}
        for w in words:
            freq[w] = freq.get(w, 0) + 1
        return [w for w, c in sorted(freq.items(), key=lambda x: x[1], reverse=True)[:5]]
    
    def update_access_pattern(self, category: str):
        """æ›´æ–°è®¿é—®æ¨¡å¼ç»Ÿè®¡"""
        if not RDS_AVAILABLE:
            return
        
        now = datetime.now()
        sql = """
        INSERT INTO memory_access_patterns (hour_of_day, day_of_week, category, access_count, last_accessed)
        VALUES (%s, %s, %s, 1, NOW())
        ON CONFLICT (hour_of_day, day_of_week, category) DO UPDATE
        SET access_count = memory_access_patterns.access_count + 1,
            last_accessed = NOW()
        """
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql, (now.hour, now.weekday(), category))
                conn.commit()
    
    def auto_maintain(self):
        """è‡ªåŠ¨ç»´æŠ¤ï¼šæ¸…ç†è¿‡æœŸè®°å¿†ã€å‡çº§é‡è¦è®°å¿†"""
        if not RDS_AVAILABLE:
            return "RDSä¸å¯ç”¨"
        
        results = []
        
        # 1. å‡çº§é«˜é¢‘è®¿é—®è®°å¿†
        sql_upgrade = """
        UPDATE memories
        SET memory_type = 'long_term', tier = 1
        WHERE access_count > 5 
        AND importance_score > 0.7
        AND memory_type = 'short_term'
        """
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql_upgrade)
                upgraded = cursor.rowcount
                conn.commit()
                results.append(f"å‡çº§ {upgraded} æ¡è®°å¿†ä¸ºé•¿æœŸè®°å¿†")
        
        # 2. æ¸…ç†è¿‡æœŸçŸ­æœŸè®°å¿†
        sql_cleanup = """
        DELETE FROM memories
        WHERE memory_type = 'short_term'
        AND tier = 3
        AND importance_score < 0.3
        AND access_count < 3
        AND created_at < NOW() - INTERVAL '30 days'
        """
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql_cleanup)
                deleted = cursor.rowcount
                conn.commit()
                results.append(f"æ¸…ç† {deleted} æ¡è¿‡æœŸè®°å¿†")
        
        # 3. è‡ªåŠ¨åˆ›å»ºå…³è”
        links = self.auto_link_memories()
        results.append(f"åˆ›å»º {links} æ¡è®°å¿†å…³è”")
        
        return "\n".join(results)


def main():
    import sys
    
    optimizer = MemoryOptimizer()
    
    if len(sys.argv) < 2:
        print("ğŸ§  è®°å¿†å±‚ä¼˜åŒ–ç³»ç»Ÿ")
        print("\nç”¨æ³•:")
        print("  python3 memory_optimizer.py init              # åˆå§‹åŒ–å¢å¼ºè¡¨")
        print("  python3 memory_optimizer.py link              # è‡ªåŠ¨åˆ›å»ºè®°å¿†å…³è”")
        print("  python3 memory_optimizer.py summary [æ—¥æœŸ]    # ç”Ÿæˆæ¯æ—¥æ‘˜è¦")
        print("  python3 memory_optimizer.py search <å…³é”®è¯>   # æ··åˆæ£€ç´¢")
        print("  python3 memory_optimizer.py suggest [æŸ¥è¯¢]    # ä¸»åŠ¨å›å¿†")
        print("  python3 memory_optimizer.py maintain          # è‡ªåŠ¨ç»´æŠ¤")
        print("\nç¤ºä¾‹:")
        print("  python3 memory_optimizer.py init")
        print("  python3 memory_optimizer.py search RDSé…ç½®")
        sys.exit(1)
    
    cmd = sys.argv[1]
    
    if cmd == 'init':
        optimizer.init_enhanced_tables()
    
    elif cmd == 'link':
        count = optimizer.auto_link_memories()
        print(f"âœ… åˆ›å»ºäº† {count} æ¡è®°å¿†å…³è”")
    
    elif cmd == 'summary':
        date = sys.argv[2] if len(sys.argv) > 2 else None
        result = optimizer.generate_daily_summary(date)
        if result:
            print(f"ğŸ“… {result['date']} æ‘˜è¦")
            print(f"è®°å¿†æ•°é‡: {result['total_memories']}")
            print(f"å…³é”®å†³ç­–: {len(result['key_decisions'])}")
            print(f"å¾…åŠäº‹é¡¹: {len(result['action_items'])}")
        else:
            print("ğŸ“­ è¯¥æ—¥æœŸæ— è®°å¿†")
    
    elif cmd == 'search':
        query = sys.argv[2]
        results = optimizer.hybrid_search(query)
        print(f"æ‰¾åˆ° {len(results)} æ¡ç›¸å…³è®°å¿†:")
        for r in results[:5]:
            print(f"  [{r[3]}] {r[4][:80]}...")
    
    elif cmd == 'suggest':
        query = sys.argv[2] if len(sys.argv) > 2 else None
        suggestions = optimizer.proactive_recall(query)
        if suggestions:
            print("ğŸ’¡ ä½ å¯èƒ½è¿˜æƒ³äº†è§£:")
            for s in suggestions:
                print(f"  â€¢ [{s[3]}] {s[4][:60]}...")
        else:
            print("ğŸ“­ æš‚æ— ç›¸å…³å»ºè®®")
    
    elif cmd == 'maintain':
        result = optimizer.auto_maintain()
        print(result)
    
    else:
        print(f"æœªçŸ¥å‘½ä»¤: {cmd}")

if __name__ == '__main__':
    main()
