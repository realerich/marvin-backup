#!/usr/bin/env python3
"""
é‚®ä»¶å½’æ¡£RDSå·¥å…·
å­˜å‚¨é‚®ä»¶ã€åˆ†ç±»ç®¡ç†ã€å…¨æ–‡æœç´¢
"""

import json
from datetime import datetime
from rds_manager import RDSManager

class EmailArchiveRDS:
    """é‚®ä»¶å½’æ¡£ç®¡ç†"""
    
    def __init__(self):
        self.rds = RDSManager()
    
    def archive_email(self, email_data, category='normal'):
        """å½’æ¡£å•å°é‚®ä»¶"""
        sql = """
        INSERT INTO emails 
        (message_id, subject, sender, sender_name, received_at, category, 
         is_read, body_summary, full_content, labels)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE
        category=VALUES(category), is_read=VALUES(is_read), updated_at=NOW()
        """
        
        # æå–å‘ä»¶äººåç§°
        sender = email_data.get('from', '')
        sender_name = ''
        if '<' in sender:
            sender_name = sender.split('<')[0].strip().strip('"')
            sender = sender.split('<')[1].strip('>')
        
        # è§£ææ—¥æœŸ
        received_at = email_data.get('date')
        try:
            from email.utils import parsedate_to_datetime
            received_at = parsedate_to_datetime(received_at)
        except:
            received_at = datetime.now()
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql, (
                    email_data.get('id'),
                    email_data.get('subject', '')[:500],
                    sender[:250],
                    sender_name[:250],
                    received_at,
                    category,
                    email_data.get('is_read', False),
                    email_data.get('body', '')[:500],
                    email_data.get('body', ''),
                    json.dumps(email_data.get('labels', []))
                ))
                conn.commit()
        
        return True
    
    def batch_archive(self, emails, category_map=None):
        """æ‰¹é‡å½’æ¡£"""
        category_map = category_map or {}
        archived = 0
        
        for email in emails:
            category = category_map.get(email.get('id'), 'normal')
            try:
                self.archive_email(email, category)
                archived += 1
            except Exception as e:
                print(f"âš ï¸ å½’æ¡£å¤±è´¥ {email.get('id')}: {e}")
        
        return f"âœ… å·²å½’æ¡£ {archived} å°é‚®ä»¶"
    
    def search_emails(self, keyword=None, category=None, sender=None, days=30, limit=50):
        """æœç´¢é‚®ä»¶"""
        conditions = ["received_at > DATE_SUB(NOW(), INTERVAL %s DAY)"]
        params = [days]
        
        if keyword:
            conditions.append("(subject LIKE %s OR body_summary LIKE %s)")
            params.extend([f"%{keyword}%", f"%{keyword}%"])
        
        if category:
            conditions.append("category = %s")
            params.append(category)
        
        if sender:
            conditions.append("sender LIKE %s")
            params.append(f"%{sender}%")
        
        sql = f"""
        SELECT * FROM emails
        WHERE {' AND '.join(conditions)}
        ORDER BY received_at DESC
        LIMIT %s
        """
        params.append(limit)
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql, params)
                return cursor.fetchall()
    
    def get_unread_summary(self, days=7):
        """è·å–æœªè¯»æ‘˜è¦"""
        sql = """
        SELECT 
            category,
            COUNT(*) as count
        FROM emails
        WHERE is_read = FALSE 
        AND received_at > DATE_SUB(NOW(), INTERVAL %s DAY)
        GROUP BY category
        """
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql, (days,))
                return cursor.fetchall()
    
    def mark_as_read(self, message_ids):
        """æ ‡è®°ä¸ºå·²è¯»"""
        if not isinstance(message_ids, list):
            message_ids = [message_ids]
        
        placeholders = ','.join(['%s'] * len(message_ids))
        sql = f"UPDATE emails SET is_read = TRUE WHERE message_id IN ({placeholders})"
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql, message_ids)
                conn.commit()
                return cursor.rowcount
    
    def get_stats(self):
        """è·å–é‚®ä»¶ç»Ÿè®¡"""
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                # æ€»æ•°
                cursor.execute("SELECT COUNT(*) as total FROM emails")
                total = cursor.fetchone()['total']
                
                # æœªè¯»æ•°
                cursor.execute("SELECT COUNT(*) as unread FROM emails WHERE is_read = FALSE")
                unread = cursor.fetchone()['unread']
                
                # æŒ‰åˆ†ç±»ç»Ÿè®¡
                cursor.execute("SELECT category, COUNT(*) as count FROM emails GROUP BY category")
                by_category = cursor.fetchall()
                
                # ä»Šæ—¥æ–°å¢
                cursor.execute("SELECT COUNT(*) as today FROM emails WHERE DATE(received_at) = CURDATE()")
                today = cursor.fetchone()['today']
                
                return {
                    'total': total,
                    'unread': unread,
                    'today': today,
                    'by_category': by_category
                }
    
    def cleanup_old_promo(self, days=30):
        """æ¸…ç†æ—§è¥é”€é‚®ä»¶"""
        sql = """
        DELETE FROM emails 
        WHERE category = 'promo' 
        AND received_at < DATE_SUB(NOW(), INTERVAL %s DAY)
        """
        
        with self.rds.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(sql, (days,))
                deleted = cursor.rowcount
                conn.commit()
        
        return f"âœ… å·²æ¸…ç† {deleted} å°æ—§è¥é”€é‚®ä»¶"


def main():
    import sys
    
    tool = EmailArchiveRDS()
    
    if len(sys.argv) < 2:
        print("ğŸ“§ é‚®ä»¶å½’æ¡£RDSå·¥å…·")
        print("\nç”¨æ³•:")
        print("  python3 email_rds.py stats                    # é‚®ä»¶ç»Ÿè®¡")
        print("  python3 email_rds.py search <å…³é”®è¯>          # æœç´¢é‚®ä»¶")
        print("  python3 email_rds.py unread                   # æœªè¯»æ‘˜è¦")
        print("  python3 email_rds.py cleanup [å¤©æ•°]           # æ¸…ç†æ—§è¥é”€é‚®ä»¶")
        sys.exit(1)
    
    cmd = sys.argv[1]
    
    if cmd == 'stats':
        stats = tool.get_stats()
        print("ğŸ“Š é‚®ä»¶ç»Ÿè®¡")
        print("=" * 40)
        print(f"æ€»æ•°é‡: {stats['total']}")
        print(f"æœªè¯»: {stats['unread']}")
        print(f"ä»Šæ—¥æ–°å¢: {stats['today']}")
        print("\næŒ‰åˆ†ç±»:")
        for c in stats['by_category']:
            print(f"  {c['category']}: {c['count']}")
    
    elif cmd == 'search':
        keyword = sys.argv[2] if len(sys.argv) > 2 else None
        results = tool.search_emails(keyword=keyword)
        print(f"æ‰¾åˆ° {len(results)} å°é‚®ä»¶:")
        for e in results[:10]:
            print(f"  [{e['category']}] {e['subject'][:50]} - {e['sender'][:30]}")
    
    elif cmd == 'unread':
        summary = tool.get_unread_summary()
        print("ğŸ“¬ æœªè¯»é‚®ä»¶æ‘˜è¦:")
        for s in summary:
            print(f"  {s['category']}: {s['count']}")
    
    elif cmd == 'cleanup':
        days = int(sys.argv[2]) if len(sys.argv) > 2 else 30
        result = tool.cleanup_old_promo(days)
        print(result)
    
    else:
        print(f"æœªçŸ¥å‘½ä»¤: {cmd}")

if __name__ == '__main__':
    main()
