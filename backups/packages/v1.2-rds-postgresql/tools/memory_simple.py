#!/usr/bin/env python3
"""
å¢å¼ºè®°å¿†æœç´¢ - çº¯æœ¬åœ°å®ç°
æ— éœ€å¤–éƒ¨APIï¼Œä½¿ç”¨å…³é”®è¯+ä¸Šä¸‹æ–‡åŒ¹é…
"""

import os
import re
import json
from pathlib import Path
from datetime import datetime
from collections import defaultdict

MEMORY_DIR = Path("/root/.openclaw/workspace/memory")
MEMORY_FILE = Path("/root/.openclaw/workspace/MEMORY.md")
INDEX_FILE = Path("/root/.openclaw/workspace/config/memory_index.json")

class SimpleMemory:
    """ç®€åŒ–ç‰ˆè®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.index = {'documents': {}, 'keywords': defaultdict(list)}
        self._build_index()
    
    def _build_index(self):
        """æ„å»ºå…³é”®è¯ç´¢å¼•"""
        print("ğŸ”„ æ„å»ºè®°å¿†ç´¢å¼•...")
        
        docs_to_index = []
        
        # åŠ è½½ MEMORY.md
        if MEMORY_FILE.exists():
            with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
                docs_to_index.append(('MEMORY.md', f.read()))
        
        # åŠ è½½ memory/*.md
        for md_file in sorted(MEMORY_DIR.glob("*.md")):
            with open(md_file, 'r', encoding='utf-8') as f:
                docs_to_index.append((md_file.name, f.read()))
        
        # ç´¢å¼•æ¯ä¸ªæ–‡æ¡£
        for filename, content in docs_to_index:
            # åˆ†å‰²æˆæ®µè½
            paragraphs = [p.strip() for p in re.split(r'\n\n+', content) if len(p.strip()) > 20]
            
            for i, para in enumerate(paragraphs):
                doc_id = f"{filename}#{i}"
                
                # æå–å…³é”®è¯
                words = self._extract_keywords(para)
                
                self.index['documents'][doc_id] = {
                    'id': doc_id,
                    'filename': filename,
                    'content': para[:500],  # é™åˆ¶é•¿åº¦
                    'keywords': words,
                    'word_count': len(para.split()),
                    'timestamp': self._extract_date(filename, para)
                }
                
                # åå‘ç´¢å¼•
                for word in words:
                    self.index['keywords'][word].append(doc_id)
        
        print(f"âœ… ç´¢å¼•å®Œæˆ: {len(self.index['documents'])} æ®µè½, {len(self.index['keywords'])} å…³é”®è¯")
    
    def _extract_keywords(self, text):
        """æå–å…³é”®è¯"""
        # æ¸…ç†æ–‡æœ¬
        text = re.sub(r'[^\w\u4e00-\u9fa5\s]', ' ', text)  # ä¿ç•™ä¸­æ–‡å’Œè‹±æ–‡
        words = text.lower().split()
        
        # è¿‡æ»¤åœç”¨è¯
        stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 
                     'çš„', 'äº†', 'å’Œ', 'æ˜¯', 'åœ¨', 'æœ‰', 'æˆ‘', 'ä½ ', 'ä»–', 'å®ƒ',
                     'this', 'that', 'these', 'those', 'to', 'of', 'in', 'for',
                     'with', 'on', 'at', 'by', 'from', 'as', 'it', 'its'}
        
        # è¿‡æ»¤çŸ­è¯å’Œåœç”¨è¯ï¼Œä½†ä¿ç•™ä¸­æ–‡
        keywords = []
        for w in words:
            if len(w) >= 2 or any('\u4e00' <= c <= '\u9fff' for c in w):
                if w not in stopwords:
                    keywords.append(w)
        
        return list(set(keywords))  # å»é‡
    
    def _extract_date(self, filename, content):
        """æå–æ—¥æœŸ"""
        # ä»æ–‡ä»¶åæå–
        date_match = re.search(r'(\d{4}-\d{2}-\d{2}|\d{8})', filename)
        if date_match:
            return date_match.group(1)
        
        # ä»å†…å®¹æå–
        date_match = re.search(r'(\d{4}-\d{2}-\d{2})', content)
        if date_match:
            return date_match.group(1)
        
        return None
    
    def search(self, query, top_k=5, context_lines=2):
        """æœç´¢è®°å¿†"""
        query_words = self._extract_keywords(query)
        
        if not query_words:
            return []
        
        # è®¡ç®—åŒ¹é…åˆ†æ•°
        scores = defaultdict(float)
        matched_keywords = defaultdict(set)
        
        for word in query_words:
            for doc_id in self.index['keywords'].get(word, []):
                scores[doc_id] += 1
                matched_keywords[doc_id].add(word)
        
        # å½’ä¸€åŒ–åˆ†æ•°
        for doc_id in scores:
            doc = self.index['documents'][doc_id]
            # è€ƒè™‘å…³é”®è¯è¦†ç›–ç‡å’Œæ–‡æ¡£é•¿åº¦
            coverage = len(matched_keywords[doc_id]) / len(query_words)
            length_bonus = min(doc['word_count'] / 100, 1.0)  # é•¿åº¦å¥–åŠ±
            scores[doc_id] = (scores[doc_id] * coverage) * (1 + length_bonus * 0.2)
        
        # æ’åºå¹¶è¿”å›å‰Kä¸ª
        sorted_results = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        
        results = []
        for doc_id, score in sorted_results[:top_k]:
            doc = self.index['documents'][doc_id]
            results.append({
                'id': doc_id,
                'filename': doc['filename'],
                'content': doc['content'],
                'score': score,
                'matched': list(matched_keywords[doc_id]),
                'date': doc['timestamp']
            })
        
        return results
    
    def add_fact(self, fact_text, category="auto"):
        """æ·»åŠ äº‹å®è®°å¿†"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        date_str = datetime.now().strftime('%Y-%m-%d')
        
        filename = f"{date_str}_fact_{timestamp}.md"
        filepath = MEMORY_DIR / filename
        
        content = f"""# è‡ªåŠ¨æå–è®°å¿†

**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ç±»åˆ«**: {category}

## å†…å®¹

{fact_text}

---
"""
        
        MEMORY_DIR.mkdir(exist_ok=True)
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # æ›´æ–°ç´¢å¼•
        words = self._extract_keywords(fact_text)
        doc_id = f"{filename}#0"
        self.index['documents'][doc_id] = {
            'id': doc_id,
            'filename': filename,
            'content': fact_text,
            'keywords': words,
            'timestamp': date_str
        }
        for word in words:
            self.index['keywords'][word].append(doc_id)
        
        return filename
    
    def get_recent(self, days=7, limit=10):
        """è·å–æœ€è¿‘è®°å¿†"""
        recent = []
        cutoff = datetime.now().timestamp() - (days * 86400)
        
        for doc_id, doc in self.index['documents'].items():
            if doc['timestamp']:
                try:
                    # è§£ææ—¥æœŸ
                    if '-' in doc['timestamp']:
                        doc_date = datetime.strptime(doc['timestamp'][:10], '%Y-%m-%d')
                        if doc_date.timestamp() >= cutoff:
                            recent.append(doc)
                except:
                    pass
        
        # æŒ‰æ—¥æœŸæ’åº
        recent.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        return recent[:limit]


def main():
    import sys
    
    memory = SimpleMemory()
    
    if len(sys.argv) < 2:
        print("ğŸ§  å¢å¼ºè®°å¿†ç³»ç»Ÿ")
        print("\nç”¨æ³•:")
        print("  python3 memory_simple.py search <æŸ¥è¯¢>    # æœç´¢è®°å¿†")
        print("  python3 memory_simple.py add <å†…å®¹>       # æ·»åŠ è®°å¿†")
        print("  python3 memory_simple.py recent [å¤©æ•°]    # æœ€è¿‘è®°å¿†")
        print("  python3 memory_simple.py stats            # ç»Ÿè®¡")
        sys.exit(1)
    
    cmd = sys.argv[1]
    
    if cmd == 'search':
        query = ' '.join(sys.argv[2:]) if len(sys.argv) > 2 else input("æœç´¢: ")
        results = memory.search(query)
        
        print(f"\nğŸ” æœç´¢: '{query}'")
        print(f"æ‰¾åˆ° {len(results)} æ¡ç»“æœ:\n")
        
        for i, r in enumerate(results, 1):
            match_level = "ğŸ”´" if r['score'] > 2 else "ğŸŸ¡" if r['score'] > 1 else "ğŸŸ¢"
            print(f"{i}. [{match_level}] {r['filename']}")
            if r['date']:
                print(f"   æ—¥æœŸ: {r['date']}")
            print(f"   åŒ¹é…: {', '.join(r['matched'][:5])}")
            print(f"   å†…å®¹: {r['content'][:120]}...")
            print()
    
    elif cmd == 'add':
        content = ' '.join(sys.argv[2:]) if len(sys.argv) > 2 else input("è®°å¿†å†…å®¹: ")
        category = input("ç±»åˆ« (auto/fact/preference/goal): ") or "auto"
        filename = memory.add_fact(content, category)
        print(f"âœ… å·²ä¿å­˜: {filename}")
    
    elif cmd == 'recent':
        days = int(sys.argv[2]) if len(sys.argv) > 2 else 7
        recent = memory.get_recent(days)
        
        print(f"\nğŸ“… æœ€è¿‘ {days} å¤©è®°å¿† ({len(recent)} æ¡):\n")
        for doc in recent:
            print(f"â€¢ [{doc.get('timestamp', 'N/A')}] {doc['content'][:80]}...")
    
    elif cmd == 'stats':
        print("ğŸ“Š è®°å¿†ç»Ÿè®¡")
        print(f"   æ®µè½æ•°: {len(memory.index['documents'])}")
        print(f"   å…³é”®è¯: {len(memory.index['keywords'])}")
        
        # æ–‡ä»¶ç»Ÿè®¡
        files = set(d['filename'] for d in memory.index['documents'].values())
        print(f"   æºæ–‡ä»¶: {len(files)}")
        
        # æœ€è¿‘æ›´æ–°
        recent = memory.get_recent(1, 3)
        if recent:
            print(f"\nğŸ“ æœ€è¿‘æ·»åŠ :")
            for r in recent:
                print(f"   â€¢ {r['content'][:60]}...")
    
    else:
        print(f"æœªçŸ¥å‘½ä»¤: {cmd}")

if __name__ == '__main__':
    main()
